## 生成 ai

基板モデルによる、追加学習なし！
チューニングとかなしで高精度！

- 画像生成 AI
  - GAN
    - 課題
      - モード崩壊
      - 多種多様な画像を単一の GAN モデルでは生成できない
  - Diffusion Model
    - 多様性
    - 画像生成の起点がノイズ画像
    - 計算量がとんでもなく多い
  - CLIP: Contrastive Language-Image Pre-Training
    - 言語と画像の事前対照学習
    - これそのものは生成 AI ではない
      - 画像とテキストを互いに比較できる形に変換するモデル！
    - OpenAI
- Transformer の登場以降, NN のスケーリング則といったものが知られるようになった
  - 大規模言語モデルのはじまり
- GPT: Generative Pretrained Transformer

### なんでいま

- 機械学種において重要な要素
  - モデル
  - データ
  - 計算機
- 時代
  - モデル 2006 とかから活発にあった
    - 計算機が追いつかない
  - 2012 とかに、3つ全てが揃った（ような）
  - 2017: Attention is All You Need
    - Transformer
      - 大規模言語モデル: LLM (Large Language Models)
    - モデルの改良 (RNN とかと比べて)
      - データによるスケールがしやすいモデル
      - レイヤーによるスケール

### 今のブームは何がすごいのか

- 利用するのに大量のデータは必要ない！
  - 学習済モデルを使っている
- 0 → 1 に使える
  - 市場調査、資料の叩き台、記事作成
- 応答が高速でコストがかからない
  - マシンパワー、アルゴリズムの進化

### 課題

- 情報の正確性
- 法律や規定の整備
- 基盤モデルの推論井コスト
- 目的に合致した指示（prompt）が難しい
- 生成結果のコントロールが困難
  - 前後の制御を配置したり
    - Amazon Recognition


## Transformer

- 何にでも使えて、強強
  - BERT, GPT-n, ViT, DALL-E
  - BERT, 将棋の ai にも
- Attention is All You Need: 2017
- マルチヘッドアテンション
- RNN を使わず Attention のみを使う
  - → 並列計算能力が向上！！
- 目的
  - 機械翻訳
  - 入力: 英文
  - 出力: 英文の次単語予測

### やってること

- 翻訳
  - ある並びの記号の集合から別の並びへのマッピング
    - 画像などの他分野にも容易に応用可能

## RNN

- 時系列データを取り扱えるように
- 出力結果が次の入力、とかだったような

## ファインチューニングと転移学習の違い

ファインチューニングの場合、学習モデルのニューラルネットワークにおける出力層の最終部分を付け替え、出力層のパラメータと入力層に近い部分のパラメータも変更する必要があります。

一方の転移学習は、出力層のパラメータのみを変更し、新たな学習モデルを作成。

## 畳み込み層

- 局所性：
  - 畳み込み層では、画像の小領域（通常は隣接ピクセルの小さいグループ）に焦点を当てます。このような局所的なパターンは、自然な画像では一般的に見られます。
  - たとえば、エッジ、テクスチャなどの特徴は、局所的なピクセルの配置に依存しています。
  - 畳み込みはこの現象を利用して、学習すべきパラメータを効率的に探索します。
- 重畳不変性：
  - 画像の中で特定の特徴（例えばエッジやテクスチャなど）が見つかる位置は、その特徴が画像の中で何を意味するかにはあまり影響を与えません。
    - そうなんだっけ、右に猫がいる、ってのはどう表現されるんだっけ
  - 畳み込み層は、この位置不変性を利用して、画像内のどの位置にある特徴でも、その特徴を同じように学習・検出することができます。
- パラメータ共有：
  - 畳み込み層では同じフィルタ（またはカーネル）が画像全体に適用されます。
  - これにより、畳み込み層はパラメータの数を大幅に減らすことができ、計算効率と汎化性能が向上します。
  - これは特に、大規模な画像や深いネットワークにとって重要です。
- 階層的特徴学習：
  - 畳み込みニューラルネットワーク(CNN)は、通常、複数の畳み込み層を含みます。
  - 最初の層は通常、低レベルな特徴（エッジや色等）を捉え、後続の層はこれらの低レベル特徴を組み合わせて、より高次元な抽象的な特徴（形状、物体等）を学習します。
  - この階層的な特徴学習は、複雑な視覚パターンを理解する上で非常に有効です。


## 疑問

- なぜ今生成 ai が途端にきてるのか
- 普通の dl とどう違うのか
- ai を使ったサービスをリリースするってなったら、今のベストプラクティスはどうなってるのか
- 畳み込みって、なんで画像に強いんだっけ
- Transformer の仕組みを再度学習


## そのほか

- business model generation

## やりたいこと

- stable diffusion のファインチューニング
- sage maker を使う
- デプロイ
  - lambda -> LLM (sage maker jumpstart でデプロイ)
- LangChain
- RAG: Retrieval Augmented Generation

## Links

- https://www.youtube.com/watch?v=YHljCU6xwdU&ab_channel=AmazonWebServicesJapan%E5%85%AC%E5%BC%8F
- https://github.com/aws-samples/aws-ml-enablement-workshop
